# KPI Dashboard Specification

**Owner**: Platform Engineering Team
**Last Updated**: 2026-02-21

---

## 1. Overview

The KPI dashboard provides executive and operational visibility into AI-Box platform health, adoption, and developer experience. It is implemented as a Grafana dashboard provisioned alongside the existing Phase 5 dashboards (Platform Operations, Security Posture, Executive Summary).

---

## 2. KPI Definitions

### 2.1 Adoption Rate
- **Definition**: Percentage of registered developers who have used AI-Box in the trailing 7 days.
- **Formula**: `(distinct users with aibox_start events in 7 days) / (total registered developers) * 100`
- **Target**: > 90% at general rollout completion.
- **Data source**: `aibox_start` telemetry events, HR developer count (manual config).

### 2.2 Startup Time p95
- **Definition**: 95th percentile of sandbox startup time across all starts in the trailing 24 hours.
- **Formula**: `histogram_quantile(0.95, rate(aibox_sandbox_startup_seconds_bucket[24h]))`
- **Target**: < 90 seconds (cold start), < 15 seconds (warm start).
- **Data source**: `aibox_sandbox_startup_seconds` histogram metric.

### 2.3 Support Ticket Volume
- **Definition**: Number of AI-Box support tickets opened in the trailing 7 days.
- **Formula**: `increase(aibox_support_tickets_total[7d])`
- **Target**: < 3 tickets/week during early adopter phase; < 10 tickets/week during general rollout.
- **Data source**: Ticketing system integration or manual Prometheus counter.

### 2.4 Fallback Frequency
- **Definition**: Percentage of development sessions where a developer falls back to local development.
- **Formula**: `(aibox_fallback_events in 7 days) / (total aibox_start events in 7 days) * 100`
- **Target**: < 5% of sessions.
- **Data source**: `aibox_fallback_events` counter (tracked when developer invokes fallback).

### 2.5 Security Events
- **Definition**: Count of security events requiring human review in the trailing 7 days.
- **Formula**: `sum(increase(aibox_security_incidents_total[7d]))`
- **Target**: Trending downward over time.
- **Data source**: SIEM integration, Falco alerts, policy violation aggregation.

---

## 3. Dashboard Layout

### Row 1: Key Metrics (y=0, h=6)

| Panel | Type | Position | Description |
|-------|------|----------|-------------|
| Adoption Rate | gauge | W=6, X=0 | Current 7-day adoption percentage |
| Startup Time p95 | stat | W=6, X=6 | Current 24h p95 startup time |
| Ticket Volume (7d) | stat | W=6, X=12 | Support tickets this week |
| Fallback Rate | gauge | W=6, X=18 | Fallback frequency percentage |

### Row 2: Trends (y=6, h=8)

| Panel | Type | Position | Description |
|-------|------|----------|-------------|
| Adoption Trend | timeseries | W=12, X=0 | Weekly adoption rate over 12 weeks |
| Startup Time Trend | timeseries | W=12, X=12 | p50/p95/p99 startup time over 4 weeks |

### Row 3: Breakdown (y=14, h=8)

| Panel | Type | Position | Description |
|-------|------|----------|-------------|
| Adoption by Team | bargauge | W=12, X=0 | Per-team adoption percentage |
| Tickets by Category | piechart | W=6, X=12 | Ticket distribution by category |
| Security Events | timeseries | W=6, X=18 | Security event trend by severity |

### Row 4: Rollout Progress (y=22, h=6)

| Panel | Type | Position | Description |
|-------|------|----------|-------------|
| Rollout Phase | stat | W=6, X=0 | Current phase (Pilot/Early/General/Mandatory) |
| Teams Migrated | gauge | W=6, X=6 | Teams completed / total teams |
| Fallback Trend | timeseries | W=12, X=12 | Fallback rate trend over 12 weeks |

---

## 4. Grafana Dashboard JSON

The dashboard is generated by the `operations.KPIDashboard()` function in
`cmd/aibox/internal/operations/kpi.go`. Key PromQL queries:

```promql
# Adoption rate
aibox_active_users_7d / aibox_total_developers * 100

# Startup time p95
histogram_quantile(0.95, rate(aibox_sandbox_startup_seconds_bucket[24h]))

# Support ticket volume (7 days)
increase(aibox_support_tickets_total[7d])

# Fallback rate
increase(aibox_fallback_events_total[7d]) / increase(aibox_sandbox_starts_total[7d]) * 100

# Security events (7 days)
sum(increase(aibox_security_incidents_total[7d]))

# Adoption by team
(count by (team) (aibox_sandbox_status{status="active_7d"})) / on(team) group_left aibox_team_size * 100

# Teams migrated
count(aibox_team_migrated == 1) / count(aibox_team_migrated)
```

---

## 5. Data Collection

### Metrics Emitted by `aibox` CLI
The following metrics are emitted by the `aibox` CLI and collected by Prometheus:

| Metric | Type | Labels | Description |
|--------|------|--------|-------------|
| `aibox_sandbox_startup_seconds` | histogram | type={cold,warm}, team | Sandbox startup duration |
| `aibox_sandbox_starts_total` | counter | team, user | Total sandbox starts |
| `aibox_active_users_7d` | gauge | | Distinct users in 7 days |
| `aibox_total_developers` | gauge | | Total registered developers |
| `aibox_fallback_events_total` | counter | team, reason | Fallback to local dev |
| `aibox_support_tickets_total` | counter | category, severity | Support tickets opened |
| `aibox_team_size` | gauge | team | Team member count |
| `aibox_team_migrated` | gauge | team | 1 if team is migrated |

### Privacy Considerations
- Startup time and fallback telemetry are aggregated; individual user sessions are not stored beyond 30 days.
- No command history, file access patterns, or code content is collected.
- Developers can opt out of non-essential telemetry via `aibox config set telemetry.enabled false` (startup time for SLA enforcement is always collected).

---

## 6. Alerting Thresholds (KPI-Specific)

| Alert | Condition | Severity | Channel |
|-------|-----------|----------|---------|
| Adoption stall | Adoption rate decreases for 2 consecutive weeks | medium | email |
| Startup SLA breach | p95 startup > 90s for 1 hour | high | slack |
| Ticket volume spike | > 2x previous week average | medium | email |
| Fallback rate spike | Fallback rate > 10% for 1 week | high | slack |
| Security event surge | > 5 incidents in 24 hours | high | slack |
